{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuWB6EqT28FE",
    "outputId": "72bd0069-4d8a-4731-90eb-02430e1db2a6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eq1WVw_c2_T6",
    "outputId": "87d972e9-8826-455f-a3be-8d1ddeee0110"
   },
   "outputs": [],
   "source": [
    "#!pip install pyyaml==5.1\n",
    "#!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#install old version of pytorch since detectron2 hasn't released packages for pytorch 1.9\n",
    "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
    "# After this step it will ask you to restart the runtime, please do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "525l_G4J2_XK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "#in case of augmentation\n",
    "#from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "#from detectron2.data import detection_utils as utils\n",
    "#import detectron2.data.transforms as T\n",
    "#import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'cat_train' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_coco_instances\n\u001b[0;32m----> 2\u001b[0m \u001b[43mregister_coco_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcat_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkey_data/train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkey_data/img\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m register_coco_instances(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat_test\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey_data/test.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey_data/img\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/datasets/coco.py:500\u001b[0m, in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_root, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)), image_root\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# 1. register a function which returns dicts\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[43mDatasetCatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_coco_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# 2. Optionally, add metadata about this dataset,\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# since they might be useful in evaluation, visualization or logging\u001b[39;00m\n\u001b[1;32m    504\u001b[0m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m    505\u001b[0m     json_file\u001b[38;5;241m=\u001b[39mjson_file, image_root\u001b[38;5;241m=\u001b[39mimage_root, evaluator_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata\n\u001b[1;32m    506\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/catalog.py:37\u001b[0m, in \u001b[0;36m_DatasetCatalog.register\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    func (callable): a callable which takes no arguments and returns a list of dicts.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        It must return the same results if called multiple times.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m callable(func), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must register a function with `DatasetCatalog.register`!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already registered!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m[name] \u001b[38;5;241m=\u001b[39m func\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset 'cat_train' is already registered!"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"cat_train\", {}, \"key_data/train.json\", \"key_data/img\")\n",
    "register_coco_instances(\"cat_test\", {}, \"key_data/test.json\", \"key_data/img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hC0-dRp52_bH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_data_dicts(directory, classes):\n",
    "    dataset_dicts = []\n",
    "    cnt=0\n",
    "    for filename in [file for file in os.listdir(directory) if file.endswith('.json')]:\n",
    "        json_file = os.path.join(directory, filename)\n",
    "        with open(json_file) as f:\n",
    "            img_anns = json.load(f)\n",
    "        record = {}\n",
    "        filename = os.path.join(directory, img_anns[\"imagePath\"])\n",
    "        record[\"file_name\"] = filename\n",
    "        ########################check your image and replace this two\n",
    "        record[\"height\"] = 736       ##########image size\n",
    "        record[\"width\"] = 1920  \n",
    "        record[\"image_id\"]=cnt  \n",
    "        #record[\"name\"]=\"fish\"\n",
    "        \n",
    "        #objjs = []\n",
    "        #objj = {\"id\": cnt,\"file_name\": filename,\"height\": 736,\"width\": 1920}\n",
    "        #objjs.append(objj)\n",
    "        #record[\"images\"] = objjs\n",
    "\n",
    "        annos = img_anns[\"shapes\"]\n",
    "        objs = []\n",
    "        pxx=[]\n",
    "        pyy=[]\n",
    "        #print('annos 2 is',annos[2])\n",
    "        iii=0\n",
    "        for anno in annos:\n",
    "          if(iii==0):\n",
    "            px = [a[0] for a in anno['points']] # x coord\n",
    "            #print('px vlues are',px)\n",
    "            py = [a[1] for a in anno['points']] # y-coord\n",
    "            poly = [(x, y) for x, y in zip(px, py)] # poly for segmentation\n",
    "            poly = [p for x in poly for p in x]\n",
    "            #print('for i',iii)\n",
    "            iii=iii+1\n",
    "          else:\n",
    "            iii=iii+1  \n",
    "            if(iii>5):  ###########orignal 5\n",
    "              pxi = [a[0] for a in anno['points']] # x coord\n",
    "              pyi = [a[1] for a in anno['points']] # y-coord\n",
    "              pt = [(x, y) for x, y in zip(pxi, pyi)] # poly for segmentation\n",
    "              pt = [p for x in pt for p in x]\n",
    "              pxx.append(pt[0])\n",
    "              #print('px array values are for y',pt[1])\n",
    "              #print('px vlues are',pxx)\n",
    "              pyy.append(pt[1])\n",
    "              #print('for i',iii)\n",
    "        bx=[np.min(px), np.min(py), np.max(px), np.max(py)]      \n",
    "        key_pt=[pxx[0],pyy[0],2,pxx[1],pyy[1],2,pxx[2],pyy[2],2,pxx[3],pyy[3],2,pxx[4],pyy[4],2,pxx[5],pyy[5],2,pxx[6],pyy[6],2]\n",
    "        #key_pt=[100,200,2,150,250,2,50,50,2,200,200,2,450,250,2,50,50,2,350,350,2]\n",
    "        print('bx is',bx,'keypoint is',key_pt)\n",
    "        obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"segmentation\": [poly],\n",
    "                \"keypoints\":[key_pt],\n",
    "                \"id\":cnt,\n",
    "                \"category_id\":0, #classes.index(anno['label']),\n",
    "                \"iscrowd\": 0,\n",
    "                \"num_keypoints\":7\n",
    "              }\n",
    "        objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        print('record is',record)\n",
    "        dataset_dicts.append(record)\n",
    "        cnt=cnt+1\n",
    "    return dataset_dicts\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "uXjLMKkl5N6K",
    "outputId": "929d34fe-2dbb-477c-8c8a-73a894b550cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7i2xlvX5N-q",
    "outputId": "c12708ba-0f95-4f5e-fa74-5327ff0567c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='cat_train',\n",
       "          json_file='key_data/train.json',\n",
       "          image_root='key_data/img',\n",
       "          evaluator_type='coco',\n",
       "          thing_classes=['fish'],\n",
       "          thing_dataset_id_to_contiguous_id={1: 0},\n",
       "          keypoint_names=['1',\n",
       "                          '2',\n",
       "                          '3',\n",
       "                          '4',\n",
       "                          '5',\n",
       "                          '6',\n",
       "                          '7',\n",
       "                          '8',\n",
       "                          '9',\n",
       "                          '10',\n",
       "                          '11',\n",
       "                          '12',\n",
       "                          '13',\n",
       "                          '14',\n",
       "                          '15',\n",
       "                          '16',\n",
       "                          '17',\n",
       "                          '18',\n",
       "                          '19',\n",
       "                          '20'],\n",
       "          keypoint_flip_map=[('18', '1')],\n",
       "          keypoint_connection_rules=[('1', '4', (155, 0, 55)),\n",
       "                                     ('2', '3', (0, 255, 55)),\n",
       "                                     ('9', '11', (255, 255, 255)),\n",
       "                                     ('1', '18', (255, 0, 155)),\n",
       "                                     ('5', '7', (0, 155, 255)),\n",
       "                                     ('1', '2', (155, 255, 0))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classes = ['fish','bh','bl','fl','sh','np','fp','tp','bhu','bhl','shu','shl']\n",
    "\n",
    "#keypoint_names = ['np','fp','tp','bhu','bhl','shu','shl']\n",
    "#keypoint_flip_map = [('np','fp'), ('np','tp'), ('bhu','bhl'),('shu','shl')]\n",
    "classes = [\"fish\"]   #####or any other parameter \n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "MetadataCatalog.get(\"cat_train\").set(thing_classes=classes)\n",
    "#classs = MetadataCatalog.get(\"cat_train\").thing_classes = [\"fish\"]\n",
    "#print(classs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############apply data augentation in images##############################\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "import detectron2.data.transforms as T\n",
    "import copy\n",
    "def custom_mapper(dataset_dict):\n",
    "    \n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    transform_list = [\n",
    "                      T.RandomContrast(0.5, 1.5),\n",
    "                      T.RandomBrightness(0.9, 1.1),\n",
    "                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "                      #T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "                      ]\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict\n",
    "class AugTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sfuJEqXr6gIe"
   },
   "outputs": [],
   "source": [
    "#keypoint_names =['np','fp','tp','bhu','bhl','shu','shl']\n",
    "keypoint_names =['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20']\n",
    "keypoint_flip_map = [('18','1')]\n",
    "MetadataCatalog.get(\"cat_train\").thing_classes = [\"fish\"]\n",
    "MetadataCatalog.get(\"cat_train\").thing_dataset_id_to_contiguous_id = {1:0}\n",
    "MetadataCatalog.get(\"cat_train\").keypoint_names = keypoint_names\n",
    "MetadataCatalog.get(\"cat_train\").keypoint_flip_map = keypoint_flip_map\n",
    "MetadataCatalog.get(\"cat_train\").evaluator_type=\"coco\"\n",
    "MetadataCatalog.get(\"cat_train\").keypoint_connection_rules = [('1','4', (155, 0, 55)),('2','3', (0, 255, 55)),('9','11', (255, 255, 255)),('1','18', (255, 0, 155)), ('5','7', (0, 155, 255)), ('1','2', (155, 255, 0)) ]\n",
    "#MetadataCatalog.get(\"cat_train\").keypoint_connection_rules = [('1','18', (0, 0, 255)), ('11','9', (0, 0, 255)), ('10','11', (0, 255, 0)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'key_data/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_dicts \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetCatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcat_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/catalog.py:58\u001b[0m, in \u001b[0;36m_DatasetCatalog.get\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not registered! Available datasets are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     55\u001b[0m             name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m     56\u001b[0m         )\n\u001b[1;32m     57\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/datasets/coco.py:500\u001b[0m, in \u001b[0;36mregister_coco_instances.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_root, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)), image_root\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# 1. register a function which returns dicts\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m DatasetCatalog\u001b[38;5;241m.\u001b[39mregister(name, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mload_coco_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# 2. Optionally, add metadata about this dataset,\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# since they might be useful in evaluation, visualization or logging\u001b[39;00m\n\u001b[1;32m    504\u001b[0m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m    505\u001b[0m     json_file\u001b[38;5;241m=\u001b[39mjson_file, image_root\u001b[38;5;241m=\u001b[39mimage_root, evaluator_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata\n\u001b[1;32m    506\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/datasets/coco.py:69\u001b[0m, in \u001b[0;36mload_coco_json\u001b[0;34m(json_file, image_root, dataset_name, extra_annotation_keys)\u001b[0m\n\u001b[1;32m     67\u001b[0m json_file \u001b[38;5;241m=\u001b[39m PathManager\u001b[38;5;241m.\u001b[39mget_local_path(json_file)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mredirect_stdout(io\u001b[38;5;241m.\u001b[39mStringIO()):\n\u001b[0;32m---> 69\u001b[0m     coco_api \u001b[38;5;241m=\u001b[39m \u001b[43mCOCO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timer\u001b[38;5;241m.\u001b[39mseconds() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     71\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m takes \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json_file, timer\u001b[38;5;241m.\u001b[39mseconds()))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pycocotools/coco.py:81\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading annotations into memory...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dataset)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation file format \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not supported\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(dataset))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'key_data/train.json'"
     ]
    }
   ],
   "source": [
    "dataset_dicts = DatasetCatalog.get(\"cat_train\")\n",
    "#dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LcwhiRLQxwDf",
    "outputId": "1c2291b0-2a64-4c06-c762-eb0edca84116"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_dicts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Visualizer\n\u001b[1;32m      7\u001b[0m fish_metadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat_train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(\u001b[43mdataset_dicts\u001b[49m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_dicts' is not defined"
     ]
    }
   ],
   "source": [
    "#trn_path = '/content/drive/MyDrive/dataset/fish_data_seg/data/train' \n",
    "#classes = ['fish']\n",
    "#dataset_dicts = get_data_dicts(trn_path,classes)\n",
    "\n",
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "fish_metadata = MetadataCatalog.get(\"cat_train\")\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    print(d['file_name'])\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=fish_metadata, scale=0.8)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.figure(figsize = (14, 10))\n",
    "    plt.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvlHovA05OFw",
    "outputId": "c1c73107-af13-4445-e7fd-586706b673f3"
   },
   "outputs": [],
   "source": [
    "#dataset_dicts = DatasetCatalog.get(\"category_test\")\n",
    "#dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DTwKJwXs5OJI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/05 22:02:14 d2.engine.defaults]: Model:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (keypoint_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (keypoint_head): KRCNNConvDeconvUpsampleHead(\n",
      "      (conv_fcn1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu1): ReLU()\n",
      "      (conv_fcn2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu2): ReLU()\n",
      "      (conv_fcn3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu3): ReLU()\n",
      "      (conv_fcn4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu4): ReLU()\n",
      "      (conv_fcn5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu5): ReLU()\n",
      "      (conv_fcn6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu6): ReLU()\n",
      "      (conv_fcn7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu7): ReLU()\n",
      "      (conv_fcn8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu8): ReLU()\n",
      "      (score_lowres): ConvTranspose2d(512, 20, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'key_data/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n\u001b[1;32m     27\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(cfg\u001b[38;5;241m.\u001b[39mOUTPUT_DIR, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mDefaultTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#trainer = AugTrainer(cfg)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m trainer\u001b[38;5;241m.\u001b[39mresume_or_load(resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/engine/defaults.py:378\u001b[0m, in \u001b[0;36mDefaultTrainer.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    376\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_model(cfg)\n\u001b[1;32m    377\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_optimizer(cfg, model)\n\u001b[0;32m--> 378\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_train_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m model \u001b[38;5;241m=\u001b[39m create_ddp_model(model, broadcast_buffers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer \u001b[38;5;241m=\u001b[39m (AMPTrainer \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mSOLVER\u001b[38;5;241m.\u001b[39mAMP\u001b[38;5;241m.\u001b[39mENABLED \u001b[38;5;28;01melse\u001b[39;00m SimpleTrainer)(\n\u001b[1;32m    382\u001b[0m     model, data_loader, optimizer\n\u001b[1;32m    383\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/engine/defaults.py:547\u001b[0m, in \u001b[0;36mDefaultTrainer.build_train_loader\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_train_loader\u001b[39m(\u001b[38;5;28mcls\u001b[39m, cfg):\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m        iterable\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m    Overwrite it if you'd like a different data loader.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_detection_train_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/config/config.py:207\u001b[0m, in \u001b[0;36mconfigurable.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(orig_func)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _called_with_cfg(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 207\u001b[0m         explicit_args \u001b[38;5;241m=\u001b[39m \u001b[43m_get_args_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m orig_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexplicit_args)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/config/config.py:245\u001b[0m, in \u001b[0;36m_get_args_from_config\u001b[0;34m(from_config_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_arg_names:\n\u001b[1;32m    244\u001b[0m         extra_kwargs[name] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[0;32m--> 245\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_config_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# forward the other arguments to __init__\u001b[39;00m\n\u001b[1;32m    247\u001b[0m ret\u001b[38;5;241m.\u001b[39mupdate(extra_kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/build.py:344\u001b[0m, in \u001b[0;36m_train_loader_from_config\u001b[0;34m(cfg, mapper, dataset, sampler)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train_loader_from_config\u001b[39m(cfg, mapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_detection_dataset_dicts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATASETS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilter_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATALOADER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFILTER_EMPTY_ANNOTATIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_keypoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mROI_KEYPOINT_HEAD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMIN_KEYPOINTS_PER_IMAGE\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKEYPOINT_ON\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproposal_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATASETS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPROPOSAL_FILES_TRAIN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLOAD_PROPOSALS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m         _log_api_usage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTRAIN[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mapper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/build.py:241\u001b[0m, in \u001b[0;36mget_detection_dataset_dicts\u001b[0;34m(names, filter_empty, min_keypoints, proposal_files, check_consistency)\u001b[0m\n\u001b[1;32m    239\u001b[0m     names \u001b[38;5;241m=\u001b[39m [names]\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names), names\n\u001b[0;32m--> 241\u001b[0m dataset_dicts \u001b[38;5;241m=\u001b[39m [DatasetCatalog\u001b[38;5;241m.\u001b[39mget(dataset_name) \u001b[38;5;28;01mfor\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m names]\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset_dicts[\u001b[38;5;241m0\u001b[39m], torchdata\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset_dicts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# ConcatDataset does not work for iterable style dataset.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;66;03m# We could support concat for iterable as well, but it's often\u001b[39;00m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;66;03m# not a good idea to concat iterables anyway.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/build.py:241\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    239\u001b[0m     names \u001b[38;5;241m=\u001b[39m [names]\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names), names\n\u001b[0;32m--> 241\u001b[0m dataset_dicts \u001b[38;5;241m=\u001b[39m [\u001b[43mDatasetCatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m names]\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset_dicts[\u001b[38;5;241m0\u001b[39m], torchdata\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset_dicts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# ConcatDataset does not work for iterable style dataset.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;66;03m# We could support concat for iterable as well, but it's often\u001b[39;00m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;66;03m# not a good idea to concat iterables anyway.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/catalog.py:58\u001b[0m, in \u001b[0;36m_DatasetCatalog.get\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not registered! Available datasets are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     55\u001b[0m             name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m     56\u001b[0m         )\n\u001b[1;32m     57\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/datasets/coco.py:500\u001b[0m, in \u001b[0;36mregister_coco_instances.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_root, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)), image_root\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# 1. register a function which returns dicts\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m DatasetCatalog\u001b[38;5;241m.\u001b[39mregister(name, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mload_coco_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# 2. Optionally, add metadata about this dataset,\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# since they might be useful in evaluation, visualization or logging\u001b[39;00m\n\u001b[1;32m    504\u001b[0m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m    505\u001b[0m     json_file\u001b[38;5;241m=\u001b[39mjson_file, image_root\u001b[38;5;241m=\u001b[39mimage_root, evaluator_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata\n\u001b[1;32m    506\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/detectron2/data/datasets/coco.py:69\u001b[0m, in \u001b[0;36mload_coco_json\u001b[0;34m(json_file, image_root, dataset_name, extra_annotation_keys)\u001b[0m\n\u001b[1;32m     67\u001b[0m json_file \u001b[38;5;241m=\u001b[39m PathManager\u001b[38;5;241m.\u001b[39mget_local_path(json_file)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mredirect_stdout(io\u001b[38;5;241m.\u001b[39mStringIO()):\n\u001b[0;32m---> 69\u001b[0m     coco_api \u001b[38;5;241m=\u001b[39m \u001b[43mCOCO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timer\u001b[38;5;241m.\u001b[39mseconds() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     71\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m takes \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json_file, timer\u001b[38;5;241m.\u001b[39mseconds()))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pycocotools/coco.py:81\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading annotations into memory...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dataset)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation file format \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not supported\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(dataset))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'key_data/train.json'"
     ]
    }
   ],
   "source": [
    "#### from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "#cfg.MODEL.DEVICE = \"cpu\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\")) #keypoint_rcnn_R_50_FPN_3x.yaml\")) \n",
    "#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"cat_train\",)\n",
    "cfg.DATASETS.TEST = ()#(\"category_test\")\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\") #keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4   #orignal 2\n",
    "cfg.SOLVER.GAMMA = 0.5\n",
    "cfg.SOLVER.BASE_LR = 0.0001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 5000   # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []  # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # hand , fish    ####number of class\n",
    "\n",
    "####################################################extra#############################\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 1\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 20     ########number of key points\n",
    "cfg.TEST.KEYPOINT_OKS_SIGMAS = np.ones((20, 1), dtype=float).tolist()\n",
    "#############################################################################\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "#trainer = AugTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zyK14kb15OMh",
    "outputId": "236cf37f-e96f-46c0-961d-c793dc04fbc4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYINjj5sv3V0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOSjwgB19v7C",
    "outputId": "b7c9b6db-c103-4391-febd-1d461d4018b6"
   },
   "outputs": [],
   "source": [
    "########for checking######################\n",
    "cls = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes\n",
    "print('NetworkModel category:%d'%( len(cls)))\n",
    "print(cls)\n",
    "\n",
    "kname = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).keypoint_names\n",
    "print('keypoint_names')\n",
    "print(kname)\n",
    "\n",
    "#krule = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).keypoint_connection_rules\n",
    "#print('keypoint_connection_rules')\n",
    "#print(krule)\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgcNcNot5Org",
    "outputId": "e6f7ac39-7713-4b5c-ce16-dcf6fe20d8f6"
   },
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"cat_test\", )\n",
    "\n",
    "#keypoint_names =['np','fp','tp','bhu','bhl','shu','shl']\n",
    "keypoint_names =['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20']\n",
    "keypoint_flip_map = [('18','1')]\n",
    "MetadataCatalog.get(\"cat_train\").thing_classes = [\"fish\"]\n",
    "MetadataCatalog.get(\"cat_train\").thing_dataset_id_to_contiguous_id = {1:0}\n",
    "MetadataCatalog.get(\"cat_train\").keypoint_names = keypoint_names\n",
    "MetadataCatalog.get(\"cat_train\").keypoint_flip_map = keypoint_flip_map\n",
    "MetadataCatalog.get(\"cat_train\").evaluator_type=\"coco\"\n",
    "MetadataCatalog.get(\"cat_train\").keypoint_connection_rules = [('1','4', (155, 0, 55)),('2','3', (0, 255, 55)),('9','11', (255, 255, 255)),('1','18', (255, 0, 155)), ('5','7', (0, 155, 255)), ('1','2', (155, 255, 0)) ]\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_metadata = MetadataCatalog.get(\"cat_test\")\n",
    "\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "import glob\n",
    "test_dataset_dicts = DatasetCatalog.get(\"cat_test\")\n",
    "size=(6,4)\n",
    "len_f=np.zeros(size)\n",
    "ii=0\n",
    "for d in random.sample(test_dataset_dicts, 6):\n",
    "    img = cv2.imread(d[\"file_name\"])      \n",
    "    #make predictions\n",
    "    outputs = predictor(img)\n",
    "    keypt = outputs[\"instances\"].pred_keypoints\n",
    "    clss = outputs[\"instances\"].pred_classes\n",
    "    #keypt = outputs[\"instances\"].pred_connection_rules\n",
    "    print(keypt)\n",
    "    size=(6,2)\n",
    "    out_f=np.zeros(size)\n",
    "    out_f[0,0]=int(keypt[0,0,0])\n",
    "    out_f[0,1]=int(keypt[0,0,1])\n",
    "    out_f[1,0]=int(keypt[0,1,0])\n",
    "    out_f[1,1]=int(keypt[0,1,1])\n",
    "    out_f[2,0]=int(keypt[0,2,0])\n",
    "    out_f[2,1]=int(keypt[0,2,1])\n",
    "    out_f[3,0]=int(keypt[0,3,0])\n",
    "    out_f[3,1]=int(keypt[0,3,1])\n",
    "    out_f[4,0]=int(keypt[0,17,0])\n",
    "    out_f[4,1]=int(keypt[0,17,1])\n",
    "    len_f[ii,0]=np.sqrt(pow((out_f[0,0]-out_f[1,0]),2)+pow((out_f[0,1]-out_f[1,1]),2)) \n",
    "    len_f[ii,1]=np.sqrt(pow((out_f[1,0]-out_f[2,0]),2)+pow((out_f[1,1]-out_f[2,1]),2))\n",
    "    len_f[ii,2]=np.sqrt(pow((out_f[0,0]-out_f[3,0]),2)+pow((out_f[0,1]-out_f[3,1]),2))\n",
    "    len_f[ii,3]=np.sqrt(pow((out_f[0,0]-out_f[4,0]),2)+pow((out_f[0,1]-out_f[4,1]),2))\n",
    "    print('ii is', ii)\n",
    "    # Use `Visualizer` to draw the predictions on the image.\n",
    "    v = Visualizer(img[:, :, ::-1], metadata = fish_metadata, scale=1)\n",
    "    #draw prediction on image\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize = (14, 10))\n",
    "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    ii=ii+1\n",
    "    print('ii is', ii)\n",
    "print('output length is is',len_f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.layers import ShapeSpec, nms, cat, cross_entropy, nonzero_tuple\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"cat_test\", )\n",
    "\n",
    "#keypoint_names =['np','fp','tp','bhu','bhl','shu','shl']\n",
    "keypoint_names =['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20']\n",
    "keypoint_flip_map = [('18','1')]\n",
    "MetadataCatalog.get(\"cat_train\").thing_classes = [\"fish\"]\n",
    "MetadataCatalog.get(\"cat_train\").thing_dataset_id_to_contiguous_id = {1:0}\n",
    "MetadataCatalog.get(\"cat_train\").keypoint_names = keypoint_names\n",
    "MetadataCatalog.get(\"cat_train\").keypoint_flip_map = keypoint_flip_map\n",
    "MetadataCatalog.get(\"cat_train\").evaluator_type=\"coco\"\n",
    "MetadataCatalog.get(\"cat_train\").keypoint_connection_rules = [('1','4', (155, 0, 55)),('2','3', (0, 255, 55)),('9','11', (255, 255, 255)),('1','18', (255, 0, 155)), ('5','7', (0, 155, 255)), ('1','2', (155, 255, 0)) ]\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_metadata = MetadataCatalog.get(\"cat_test\")\n",
    "\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "import glob\n",
    "test_dataset_dicts = DatasetCatalog.get(\"cat_test\")\n",
    "size=(6,4)\n",
    "len_f=np.zeros(size)\n",
    "ii=0\n",
    "for d in range(1, 4):\n",
    "    img = cv2.imread('key_data/jaw_defor/T'+str(d)+'.jpg')      \n",
    "    #make predictions\n",
    "    outputs = predictor(img)\n",
    "    keypt = outputs[\"instances\"].pred_keypoints\n",
    "    clss = outputs[\"instances\"].pred_classes\n",
    "    scores = outputs['instances'].scores.to(\"cpu\").numpy()\n",
    "    boxes = outputs[\"instances\"].pred_boxes\n",
    "    print(scores[0])\n",
    "    #keypt = outputs[\"instances\"].pred_connection_rules\n",
    "    print(keyp[0])\n",
    "    size=(6,2)\n",
    "    out_f=np.zeros(size)\n",
    "    nms(boxes = boxes, scores = scores, iou_threshold=0.3)\n",
    "    #keypt=keypt[0]\n",
    "    out_f[0,0]=int(keypt[0,0,0])\n",
    "    out_f[0,1]=int(keypt[0,0,1])\n",
    "    out_f[1,0]=int(keypt[0,1,0])\n",
    "    out_f[1,1]=int(keypt[0,1,1])\n",
    "    out_f[2,0]=int(keypt[0,2,0])\n",
    "    out_f[2,1]=int(keypt[0,2,1])\n",
    "    out_f[3,0]=int(keypt[0,3,0])\n",
    "    out_f[3,1]=int(keypt[0,3,1])\n",
    "    out_f[4,0]=int(keypt[0,17,0])\n",
    "    out_f[4,1]=int(keypt[0,17,1])\n",
    "    len_f[ii,0]=np.sqrt(pow((out_f[0,0]-out_f[1,0]),2)+pow((out_f[0,1]-out_f[1,1]),2)) \n",
    "    len_f[ii,1]=np.sqrt(pow((out_f[1,0]-out_f[2,0]),2)+pow((out_f[1,1]-out_f[2,1]),2))\n",
    "    len_f[ii,2]=np.sqrt(pow((out_f[0,0]-out_f[3,0]),2)+pow((out_f[0,1]-out_f[3,1]),2))\n",
    "    len_f[ii,3]=np.sqrt(pow((out_f[0,0]-out_f[4,0]),2)+pow((out_f[0,1]-out_f[4,1]),2))\n",
    "    print('ii is', ii)\n",
    "    # Use `Visualizer` to draw the predictions on the image.\n",
    "    v = Visualizer(img[:, :, ::-1], metadata = fish_metadata, scale=1)\n",
    "    #draw prediction on image\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize = (14, 10))\n",
    "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    ii=ii+1\n",
    "    print('ii is', ii)\n",
    "print('output length is is',len_f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(outputs)\n",
    "cv2.imwrite('otpt.jpg',v.get_image()[:, :, ::-1])\n",
    "scores = outputs['instances'].scores.to(\"cpu\").numpy()\n",
    "labels = outputs['instances'].pred_classes .to(\"cpu\").numpy()\n",
    "\n",
    "boxes = outputs[\"instances\"].pred_boxes\n",
    "keypt = outputs[\"instances\"].pred_keypoints\n",
    "clss = outputs[\"instances\"].pred_classes\n",
    "#keypt = outputs[\"instances\"].pred_connection_rules\n",
    "print(keypt,scores)\n",
    "print('class is', clss)\n",
    "print('boxes is is', boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRbgdDOMByxB"
   },
   "outputs": [],
   "source": [
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "#We are using the pre-trained Detectron2 model, as shown below.\n",
    "cfg = get_cfg()\n",
    "#cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "# load the pre trained model from Detectron2 model zoo\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6 # set a custom testing threshold\n",
    "#fish_metadata = MetadataCatalog.get(\"cat_train\")\n",
    "print(fish_metadata)\n",
    "def cv2_imshow(im):\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(25,7.5)), plt.imshow(im), plt.axis('off');\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = DefaultPredictor(cfg)\n",
    "#im = cv2.imread(\"waving.jpg\")\n",
    "#im = cv2.imread(\"test.jpeg\")\n",
    "im = cv2.imread(\"test2.jpeg\")\n",
    "outputs = predictor(im)\n",
    "print(outputs)\n",
    "o = outputs[\"instances\"]\n",
    "print(\"###########################################################\")\n",
    "\n",
    "\n",
    "\n",
    "idxofClass = [i for i, x in enumerate(list(outputs['instances'].pred_classes)) if x == 15]\n",
    "\n",
    "#Create new class, boxes, scores & masks\n",
    "classes = o.pred_classes[idxofClass]\n",
    "scores = o.scores[idxofClass]\n",
    "boxes = o.pred_boxes[idxofClass]\n",
    "print('classes, score, box is',classes, scores, boxes)\n",
    "#masks = o.pred_masks[idxofClass]\n",
    "\n",
    "#Define new instance and set the new values to new instance. Note: detectron2 module provides this method set.\n",
    "obj = detectron2.structures.Instances(image_size=(480, 640))\n",
    "\n",
    "obj.set('pred_classes', classes)\n",
    "obj.set('scores', scores)\n",
    "obj.set('pred_boxes', boxes)\n",
    "#obj.set('pred_masks', masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LsmjShaFCDO4",
    "outputId": "df8d51a1-ffbd-493f-d254-f3858e172982"
   },
   "outputs": [],
   "source": [
    "v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=fish_metadata, \n",
    "                   scale=0.8, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "plt.figure(figsize = (14, 10))\n",
    "plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"valid_data\", {}, \"key_data/validation.json\", \"key_data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(\"valid_data\").thing_classes = [\"fish\"]\n",
    "pose_metadata = MetadataCatalog.get(\"valid_data\").set(thing_classes=[\"fish\"])\n",
    "val_dicts = DatasetCatalog.get(\"valid_data\")\n",
    "print(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the final weights\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "# set the testing threshold for this model\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "# List of the dataset names for validation. Must be registered in DatasetCatalog\n",
    "cfg.DATASETS.TEST = (\"validation_data\", )\n",
    "# set up predictor\n",
    "from detectron2.engine import DefaultPredictor\n",
    "# Create a simple end-to-end predictor with the given config\n",
    "# that runs on single device for a single input image.\n",
    "predictor = DefaultPredictor(cfg)\n",
    "import random\n",
    "#for drawing predictions on images\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "#to display an image\n",
    "#randomly select images\n",
    "ii=0\n",
    "for d in random.sample(val_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])      \n",
    "    #make predictions\n",
    "    outputs = predictor(img)\n",
    "    keypt = outputs[\"instances\"].pred_keypoints\n",
    "    clss = outputs[\"instances\"].pred_classes\n",
    "    #keypt = outputs[\"instances\"].pred_connection_rules\n",
    "    print(keypt)\n",
    "    size=(5,2)\n",
    "    out_f=np.zeros(size)\n",
    "    out_f[0,0]=int(keypt[0,0,0])\n",
    "    out_f[0,1]=int(keypt[0,0,1])\n",
    "    out_f[1,0]=int(keypt[0,1,0])\n",
    "    out_f[1,1]=int(keypt[0,1,1])\n",
    "    out_f[2,0]=int(keypt[0,2,0])\n",
    "    out_f[2,1]=int(keypt[0,2,1])\n",
    "    out_f[3,0]=int(keypt[0,3,0])\n",
    "    out_f[3,1]=int(keypt[0,3,1])\n",
    "    out_f[4,0]=int(keypt[0,4,0])\n",
    "    out_f[4,1]=int(keypt[0,4,1])\n",
    "    len_f[ii,0]=np.sqrt(pow((out_f[3,0]-out_f[4,0]),2)+pow((out_f[3,1]-out_f[4,1]),2)) \n",
    "    len_f[ii,1]=np.sqrt(pow((out_f[0,0]-out_f[2,0]),2)+pow((out_f[0,1]-out_f[2,1]),2))\n",
    "    len_f[ii,2]=np.sqrt(pow((out_f[0,0]-out_f[1,0]),2)+pow((out_f[0,1]-out_f[1,1]),2))\n",
    "    ii=ii+1\n",
    "    print('ii is', ii)\n",
    "    # Use `Visualizer` to draw the predictions on the image.\n",
    "    v = Visualizer(img[:, :, ::-1], metadata = fish_metadata, scale=1)\n",
    "    #draw prediction on image\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize = (14, 10))\n",
    "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    ii=ii+1\n",
    "    print('ii is', ii)\n",
    "print('output length is is',len_f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test evaluation\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"valid_data\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"valid_data\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Key_pnt_detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
